# 名词解释
- network namespace

> 隔离Linux网络设备，以及IP地址、端口、路由表、防火墙规则等网络资源。

- veth pair

> 连接两块虚拟以太网卡(veth)，一端发送的数据在另一端接收。常用于连接两个跨namespace的网络设备，如网桥和容器内的veth0网卡。

- Linux Bridge

> 二层网络设备，虚拟的网络交换机，连接同一个主机下的不同网络设备，通过Mac地址决定从哪个端口转发出去。

- 网卡的混杂模式

> 打开混杂模式后，一个网卡把所有接收到的网络流量都交给CPU，而不是只把Mac地址是它自己的单播帧以及多播、广播帧交给CPU。

# CNI

CNI是容器网络接口的缩写，K8s通过CNI统一了用于配置网络的插件接口，具体工作原理如下：
![](/images/kubernetes/WeChat5e85f68dcf55b9379fd14c85ebea084d.png)

1. K8s调用CRI创建pause容器，生成对应的network namespace，此时应用容器并未创建；
2. CNI driver根据配置调用CNI插件；
3. CNI插件给pause容器配置正确的网络，Pod内的其它容器共用pause容器网络栈；
4. CNI插件在主机上进行相关的网络配置，以便实现pod与外部网络的互通；

# 网络方案
## flannel
flannel将某一协议的数据包封装在另一种网络协议中进行路由转发，以此构建overlay网络。有三种比较成熟的backend模式，分别是：UDP、VXLAN、Host Gateway。

### UDP模式
UDP模式底层基于tun设备，实现原理可参考下图：
![](/images/kubernetes/WechatIMG486.png)
假设容器A ping 容器B的ip，源ip为10.244.1.96，目的ip为10.244.2.194，数据包将经过以下路径到达容器B：

1. 容器A查找本地路由表，发现访问10.244.0.0/16网段的下一跳是10.244.1.1；
2. 容器A发出arp请求，cni0网桥返回网桥的Mac地址；
3. 容器A封装数据包，目的ip地址为10.244.2.194，Mac地址为cni0网桥的Mac地址；
4. cni0网桥收到3层数据包后，查找主机路由表，发现10.244.0.0/16网段的数据是发给flannel0网卡；
5. flannel0网卡是个tun设备，收到数据后，通过设备文件将数据包转发给flanneld进程；
6. flanneld进程通过查找etcd可以获得10.244.2.0/24网段对应的对端主机ip和flanneld监听端口，将raw ip包封装成udp包，并通过主机网络发送至对端flanneld进程；
7. 对端flanneld进程收到数据包后进行解包，并将数据包转发给flannel0网卡；
8. flannel0网卡收到数据包后，查找主机路由表，发现10.244.2.0/24网段的数据包转发给cni0网桥，此时不知道10.244.2.194的Mac地址，向cni0网桥发起广播，得到容器B eth0的Mac地址；
9. 设置目的Mac地址后，通过cni0网桥发出，cni0网桥二层交换转发到容器eth0网卡，至此整个流程结束；
10. 回程报文按上述数据流原路返回。

### VXLAN模式
#### VXLAN原理
VXLAN的封包如下图：
![](/images/kubernetes/vxlanpackage.png)

- VTEP： 进行VXLAN报文的处理，可以是交换机，也可以是宿主机
- VNI：一个VNI号对应一个租户
- etcd：分配主机ip段
- FDB表：交换机通过mac地址查找端口号的表，如果不在表中，向所有不是源端口的端口发送数据包，成为洪泛。

![](/images/kubernetes/vxlan.png)

VXLAN转发过程：原始报文经过VTEP，被Linux内核添加上VXLAN包头及外层的UDP头部，再发送出去，对端VTEP接收到VXLAN报文后拆除外层UDP头部，并根据VXLAN头部的VNI把原始报文发送到目的服务器。

一个VXLAN报文需要确定两个地址信息：内层报文（对应目的虚拟机/容器）的MAC地址和外层报文（对应目的虚拟机/容器所在宿主机上的VTEP）IP地址。一般有多播和控制中心两种方式获得以上信息。

多播方式下VXLAN的转发流程为：

1. 容器172.17.1.2/24 ping 172.17.1.3，查本地路由表，发现是转发到veth0；
2. 不知道目的mac地址，发起arp请求，源Mac地址为veth0 Mac 地址，目的Mac地址为255.255.255.255；
3. Arp包经过veth0、br0到达VTEP，VTEP查找FDB表发现目的Mac地址不在转发表内，又配置了多播组，将arp包发给多播组，组内的所有VTEP收到报文；
4. 其它VTEP收到报文后，去掉VXLAN包头，发现目的mac地址是255.255.255.255，是广播报文，转发给网桥，网桥广播给所有容器；
5. 容器记录源ip和源Mac地址的arp表，VTEP记录Mac地址到VTEP ip的FDB表；
6. 命中的容器并返回Mac地址，arp请求得到响应；
7. Ping包封装目的ip和目的Mac地址，发送至VXLAN0，VXLAN0查找FDB表，发现有记录，转发到对端VTEP端口，对端收到后解包，根据目的mac地址通过网桥转发到对端容器。

由于多播的方式会导致arp/fdb学习时的报文浪费，实际生产中很少用到vxlan的多播方式，而是从控制中心同步arp表和fdb表中需要的映射关系。做法为，当内核发现需要的arp或fdb表项不存在时，发送l2miss或l3miss事件给订阅的应用程序，应用程序获取事件后，更新内核表项。可以概括为下图的形式：
![](/images/kubernetes/WechatIMG487.jpeg)
对照多播的方式，使用l2miss&l3miss方案存在以下差异：

1. 在第3步arp报文到达VXLAN0时，VXLAN0启用了ARP代理，所谓arp代理，意思是不管arp请求的内容，统一截获并返回Mac地址。在这一步，内核抛出l2miss事件，flannel的daemon进程捕获这一事件后，从etcd查找容器B的IP对应的Mac地址，存入主机arp表，VXLAN0命中后，恢复arp报文；
2. 在第5步多播的方式主机学习了FDB表，但是在控制中心的方式下，VTEP设备收到报文的目的Mac地址后，不知道要转发给哪个VTEP，此时会抛出l3miss事件。同样的，daemon进程捕获后更新FDB表项，记录目的Mac地址与对端VTEP IP的对应关系，再由VTEP封包后发出。

#### Flannel VXLAN模式下的实现
早期的flannel方案采用l2miss&l3miss，将在容器arp请求到VTEP时，VTEP开启本地ARP代答功能，flannel daemon进程捕获l2miss事件后，从etcd中查找路由并添加；daemon进程捕获l3miss事件后，在fdb表加入映射关系。

最新版的flannel则移除了l2miss&l3miss方式，改成三层路由的实现方案，原理参考下图：
![](/images/kubernetes/WechatIMG490.png)

- One Route：

```
172.17.2.0/24 via 172.17.1.0 dev flannel.1 onlink
```

- One ARP:

```
172.17.2.0 dev flannel.1 lladdr 7a:2c:d0:7f:48:3f PERMANENT
```
- One FDB:

```
7a:2c:d0:7f:48:3f dev flannel.1 dst 192.168.1.3 self permanent
```

从容器veth0网卡出来的数据包下一跳是flannel.1网卡，flannel.1网卡接收到ip数据包后，查找arp表项找到对应的Mac地址，再由Mac地址查找FDB表项找到对端VTEP的物理IP地址。对端VTEP接收到数据包后，查找路由表发现172.17.2.2的数据包要发给cni0网桥，并通过arp查找到容器的Mac地址，通过网桥发送到容器。

通过三层路由的方式，解决了l2miss&l3miss方案的缺陷：

- 每一台 Host 需要配置所有需要互通 Guest 路由，路由记录会膨胀，不适合大型组网
- 通过 netlink 通知学习路由的效率不高
- Flannel Daemon 异常后无法持续维护 ARP 和 FDB 表，从而导致网络不通

## Calico
Calico有两种模式，一种是基于ipip隧道搭建，另一种是基于vRouter将物理机作为虚拟路由器，要理解这个方式需要先了解BGP。

![](/images/kubernetes/WechatIMG491.jpeg)
BGP协议意为边界网关协议(Border Gateway Protocol)，按照运行方式可以分为eBGP和iBGP。

- AS：网络自治系统，通过BGP与其他AS网络交换路由信息；
- iBGP：AS内部的BGP Speaker，与同一个AS内部的iBGP、eBGP交换路由信息；
- eBGP：AS边界的BGP Speaker，与同一个AS内部的iBGP、其他AS的eBGP交换路由信息；

BGP 设备将最优路由加入 BGP 路由表，形成 BGP 路由。BGP 设备与对等体建立邻居关系后，采取以下交互原则：

1. 从 IBGP 对等体获得的 BGP 路由， BGP 设备只发布给它的 EBGP 对等体。
2. 从 EBGP 对等体获得的 BGP 路由， BGP 设备发布给它所有 EBGP 和 IBGP 对等体。
3. 当存在多条到达同一目的地址的有效路由时， BGP 设备只将最优路由发布给对等体。
4. 路由更新时， BGP 设备只发送更新的 BGP 路由。
5. 所有对等体发送的路由， BGP 设备都会接收。
Calico的内部实现机制：
![](/images/kubernetes/WechatIMG492.png)

- Felix负责编写主机路由和ACL(iptables)规则到内核中；
- BGP Client读取Felix写入内核的路由信息，分发到集群的其它工作节点上。

Calico的报文转发路径：Caclico的pod网络配置都是一样的，Mac地址是默认的eeee-eeee-eeee-eeee，容器1 ping 容器2时：

1. 查路由表，发现配置了默认的下一跳；
2. Arp查找下一跳Mac地址，通过veth pair到达主机网卡，主机网卡配置了arp代理，返回主机网卡的Mac地址；
3. 发送数据包到主机网卡，接收到之后，查找路由表，发送到物理网络的对端机器上；
4. 对端机器收到数据包后，查找路由表，通过veth pair转发到pod的网卡；

![](/images/kubernetes/WechatIMG493.png)

## Macvlan
macvlan可以看做是物理以太网卡的虚拟子接口。每个macvlan都有区别于父接口的Mac地址，可以像普通网络接口一样分配ip地址。Macvlan一共支持5种模式，分别是：

1. bridge模式
2. VEPA模式
3. Private模式
4. Passthru模式
5. Source模式

重点介绍下bridge和VEPA模式。
### bridge模式
![](/images/kubernetes/WechatIMG494.png)
在bridge模式下，共享父接口的两个子接口可以直接通讯，广播帧会被洪泛到连接在“网桥”上的所有其他子接口和物理接口。这有点类似于Linux网桥，但并未使用生成树协议，因此不会有二层环路问题。
### VEPA模式
![](/images/kubernetes/WechatIMG495.png)
在VEPA模式下，所有从macvlan子接口发出的流量，全部发往父接口，因为生成树协议的原因，两个子接口无法直接通讯，因此流量被转发到外部交换机。在原Mac地址和目的Mac地址都是同一端口的情况下，外部交换机需要支持hairpin。

# 参考文档
- 《Kubernetes网络权威指南》---杜军 [https://weread.qq.com/web/reader/829328f071a74c6182975ccke4d32d5015e4da3b7fbb1fa](https://weread.qq.com/web/reader/829328f071a74c6182975ccke4d32d5015e4da3b7fbb1fa)
- 生成树协议 [http://www.routeralley.com/guides/stp.pdf](http://www.routeralley.com/guides/stp.pdf)
- BGP漫谈 [https://zhuanlan.zhihu.com/p/25433049](https://zhuanlan.zhihu.com/p/25433049)
- BGP路由协议技术详解 [https://zhuanlan.zhihu.com/p/126754314](https://zhuanlan.zhihu.com/p/126754314)